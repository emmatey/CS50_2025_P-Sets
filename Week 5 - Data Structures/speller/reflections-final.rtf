{\rtf1\ansi\deff3\adeflang1025
{\fonttbl{\f0\froman\fprq2\fcharset0 Times New Roman;}{\f1\froman\fprq2\fcharset2 Symbol;}{\f2\fswiss\fprq2\fcharset0 Arial;}{\f3\froman\fprq2\fcharset0 Liberation Serif{\*\falt Times New Roman};}{\f4\fnil\fprq0\fcharset2 OpenSymbol{\*\falt Arial Unicode MS};}{\f5\fmodern\fprq1\fcharset0 Liberation Mono{\*\falt Courier New};}{\f6\fswiss\fprq2\fcharset0 Liberation Sans{\*\falt Arial};}{\f7\fmodern\fprq1\fcharset0 Noto Sans Mono CJK SC;}{\f8\fnil\fprq2\fcharset0 Noto Sans CJK SC;}{\f9\fnil\fprq2\fcharset0 Noto Serif CJK SC;}{\f10\fnil\fprq2\fcharset0 Noto Sans Devanagari;}{\f11\fswiss\fprq0\fcharset128 Noto Sans Devanagari;}}
{\colortbl;\red0\green0\blue0;\red0\green0\blue255;\red0\green255\blue255;\red0\green255\blue0;\red255\green0\blue255;\red255\green0\blue0;\red255\green255\blue0;\red255\green255\blue255;\red0\green0\blue128;\red0\green128\blue128;\red0\green128\blue0;\red128\green0\blue128;\red128\green0\blue0;\red128\green128\blue0;\red128\green128\blue128;\red192\green192\blue192;}
{\stylesheet{\s0\snext0\widctlpar\hyphpar0\ltrpar\kerning1\cf0\rtlch\af10\afs24\alang1081\ltrch\hich\af3\afs24\alang1033\dbch\af9\langfe2052\loch\f3\fs24\lang1033 Normal;}
{\s2\sbasedon17\snext18\ilvl1\outlinelevel1\sb200\sa120\rtlch\af10\afs36\ab\ltrch\hich\af3\afs36\ab\dbch\af9\loch\f3\fs36\b heading 2;}
{\s3\sbasedon17\snext18\ilvl2\outlinelevel2\sb140\sa120\rtlch\af10\afs28\ab\ltrch\hich\af3\afs28\ab\dbch\af9\loch\f3\fs28\b heading 3;}
{\*\cs15\snext15\rtlch\af4\ltrch\hich\af4\dbch\af4\loch\f4 Bullets;}
{\*\cs16\snext16\rtlch\af5\ltrch\hich\af5\dbch\af7\loch\f5 Source Text;}
{\s17\sbasedon0\snext18\sb240\sa120\keepn\rtlch\af10\afs28\ltrch\hich\af6\afs28\dbch\af8\loch\f6\fs28 Heading;}
{\s18\sbasedon0\snext18\sl276\slmult1\sb0\sa140 Body Text;}
{\s19\sbasedon18\snext19\rtlch\af11\ltrch List;}
{\s20\sbasedon0\snext20\sb120\sa120\noline\rtlch\af11\afs24\ai\ltrch\fs24\i caption;}
{\s21\sbasedon0\snext21\noline\rtlch\af11\ltrch Index;}
{\s22\sbasedon0\snext18\sb0\sa283\brdrt\brdrnone\brdrl\brdrnone\brdrb\brdrdb\brdrw1\brdrcf15\brsp0\brdrr\brdrnone\noline\rtlch\afs12\ltrch\fs12 Horizontal Line;}
}{\*\listtable{\list\listtemplateid1
{\listlevel\levelnfc255\leveljc0\levelstartat1\levelfollow2{\leveltext \'00;}{\levelnumbers;}\fi0\li0}
{\listlevel\levelnfc255\leveljc0\levelstartat1\levelfollow2{\leveltext \'00;}{\levelnumbers;}\fi0\li0}
{\listlevel\levelnfc255\leveljc0\levelstartat1\levelfollow2{\leveltext \'00;}{\levelnumbers;}\fi0\li0}
{\listlevel\levelnfc255\leveljc0\levelstartat1\levelfollow2{\leveltext \'00;}{\levelnumbers;}\fi0\li0}
{\listlevel\levelnfc255\leveljc0\levelstartat1\levelfollow2{\leveltext \'00;}{\levelnumbers;}\fi0\li0}
{\listlevel\levelnfc255\leveljc0\levelstartat1\levelfollow2{\leveltext \'00;}{\levelnumbers;}\fi0\li0}
{\listlevel\levelnfc255\leveljc0\levelstartat1\levelfollow2{\leveltext \'00;}{\levelnumbers;}\fi0\li0}
{\listlevel\levelnfc255\leveljc0\levelstartat1\levelfollow2{\leveltext \'00;}{\levelnumbers;}\fi0\li0}
{\listlevel\levelnfc255\leveljc0\levelstartat1\levelfollow2{\leveltext \'00;}{\levelnumbers;}\fi0\li0}\listid1}
}{\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}}{\*\generator LibreOffice/25.8.3.2$Linux_X86_64 LibreOffice_project/580$Build-2}{\info{\creatim\yr2025\mo12\dy2\hr20\min13}{\revtim\yr2025\mo12\dy2\hr20\min21}{\printim\yr0\mo0\dy0\hr0\min0}}{\*\userprops}\deftab709
\hyphauto1\viewscale120\formshade\nobrkwrptbl\paperh15840\paperw12240\margl1134\margr1134\margt1134\margb1134\sectd\sbknone\sftnnar\saftnnrlc\sectunlocked1\pgwsxn12240\pghsxn15840\marglsxn1134\margrsxn1134\margtsxn1134\margbsxn1134\ftnbj\ftnstart1\ftnrstcont\ftnnar\fet\aftnrstcont\aftnstart1\aftnnrlc
{\*\ftnsep\chftnsep}\pgndec\pard\plain \s3\ilvl2\outlinelevel2\sb140\sa120\rtlch\af10\afs28\ab\ltrch\hich\af3\afs28\ab\dbch\af9\loch\f3\fs28\b\ql\sb140\sa120\ltrpar{\rtlch\ab0\ltrch\b0
Introduction and Na\u239\'efve Solution}
{\rtlch\ab0\ltrch\hich\ab0\dbch\ab0\loch\b0\par}\pard\plain \s18\sl276\slmult1\sb0\sa140\ql\ltrpar{\rtlch\ab0\ltrch\b0
In this pset, I was tasked with implementing a hash table. The context of the hash table was a spell-checking program. The goal of the program was to spell-check the input text as fast as possible.}
{\rtlch\ab0\ltrch\hich\ab0\dbch\ab0\loch\b0\par}\pard\plain \s18\sl276\slmult1\sb0\sa140\ql\ltrpar{\rtlch\ab0\ltrch\b0
The na\u239\'efve solution to this problem would be to iterate over the array of valid words, comparing the input word at each step until either said word is found, or the end of the dictionary is reached. This would work, but it would also be extremely slow.}
{\rtlch\ab0\ltrch\hich\ab0\dbch\ab0\loch\b0\par}\pard\plain \s18\sl276\slmult1\sb0\sa140\ql\fi0\li0\lin0\ri0\rin0\ltrpar{\rtlch\ab0\ltrch\b0
The time complexity would be O(N\u8901\'3fdict_size) or O(NM); this is a form of quadratic time.}
{\rtlch\ab0\ltrch\hich\ab0\dbch\ab0\loch\b0\par}\pard\plain \s3\ilvl2\outlinelevel2\sb140\sa120\rtlch\af10\afs28\ab\ltrch\hich\af3\afs28\ab\dbch\af9\loch\f3\fs28\b\sl276\slmult1\ql\sb0\sa140\ltrpar{\rtlch\ab0\ltrch\b0
Hash Table Fundamentals}
{\rtlch\ab0\ltrch\hich\ab0\dbch\ab0\loch\b0\par}\pard\plain \s18\sl276\slmult1\sb0\sa140\ql\ltrpar{\rtlch\ab0\ltrch\b0
A much faster way to search the dictionary is by using a hash table. This data structure works by converting each input word into a number, i.e., "hashing," and using that number as a storage location, i.e., an array index.}
{\rtlch\ab0\ltrch\hich\ab0\dbch\ab0\loch\b0\par}\pard\plain \s18\sl276\slmult1\sb0\sa140\ql\ltrpar{\rtlch\ab0\ltrch\b0
By "hashing," we mean feeding an arbitrary piece of information to a hash function. A hash function converts this information into an integer we can use as an index in an array to store information at. A crucial thing to remember about a hash function is that it's 'deterministic,' meaning that every time you feed the same data into the function, you will ALWAYS get the same result. A good hash function also will have wildly different outputs based on small changes to an input; this is known as "avalanching" and is required to evenly distribute datasets that contain patterns.}
{\rtlch\ab0\ltrch\hich\ab0\dbch\ab0\loch\b0\par}\pard\plain \s18\sl276\slmult1\sb0\sa140\ql\ltrpar{\rtlch\ab0\ltrch\b0
In an initial setup phase, the dictionary itself is "hashed," meaning that an array is instantiated, and then for every word in the dictionary, the given word is converted into a number, and then it is stored at that location in the array. In the event that this location is occupied already, we have a situation known as a "collision."}
{\rtlch\ab0\ltrch\hich\ab0\dbch\ab0\loch\b0\par}\pard\plain \s18\sl276\slmult1\sb0\sa140\ql\ltrpar{\rtlch\ab0\ltrch\b0
Assuming there's either no collision, or a collision is dealt with, we now, in memory, have a processed dictionary whose data is in the shape of a hash table. And as words from the input text come in, we can use this structure to quickly search if the input word is within the dictionary by "hashing" the word. This will return a number that I can then use to check one, and only one, location in an array, instead of EVERY location in the array like with the na\u239\'efve solution.}
{\rtlch\ab0\ltrch\hich\ab0\dbch\ab0\loch\b0\par}\pard\plain \s22\sb0\sa283\brdrt\brdrnone\brdrl\brdrnone\brdrb\brdrdb\brdrw1\brdrcf15\brsp0\brdrr\brdrnone\noline\rtlch\afs12\ltrch\fs12\sl276\slmult1\ql\sb0\sa140\ltrpar\rtlch\ab0\ltrch\b0

{\rtlch\ab0\ltrch\hich\ab0\dbch\ab0\loch\b0\par}\pard\plain \s2\ilvl1\outlinelevel1\sb200\sa120\rtlch\af10\afs36\ab\ltrch\hich\af3\afs36\ab\dbch\af9\loch\f3\fs36\b\sl276\slmult1\ql\sb0\sa140\ltrpar{\rtlch\ab0\ltrch\b0
Collision Resolution Methods}
{\rtlch\ab0\ltrch\hich\ab0\dbch\ab0\loch\b0\par}\pard\plain \s3\ilvl2\outlinelevel2\sb140\sa120\rtlch\af10\afs28\ab\ltrch\hich\af3\afs28\ab\dbch\af9\loch\f3\fs28\b\sl276\slmult1\ql\sb0\sa140\ltrpar{\rtlch\ab0\ltrch\b0
1. Open Addressing (Linear Probing)}
{\rtlch\ab0\ltrch\hich\ab0\dbch\ab0\loch\b0\par}\pard\plain \s18\sl276\slmult1\sb0\sa140\ql\ltrpar{\rtlch\ab0\ltrch\b0
With this method, if a collision happens, the data structure will simply move to the neighboring array index, and then put the value there instead.}
{\rtlch\ab0\ltrch\hich\ab0\dbch\ab0\loch\b0\par}\pard\plain \s18\sl276\slmult1\sb0\sa140\ql\ltrpar{\rtlch\ab0\ltrch\b0
The advantage of this is speed, as a computer is fastest at processing contiguous chunks of data than disparate data at various locations in RAM.}
{\rtlch\ab0\ltrch\hich\ab0\dbch\ab0\loch\b0\par}\pard\plain \s18\sl276\slmult1\sb0\sa140\ql\ltrpar{\rtlch\ab0\ltrch\b0
The disadvantage, though, is that it's more complex to retrieve data. For example, imagine what conditions you would check if writing a retrieval algorithm, i.e., a method to check if a given datum is present in the data structure. I would imagine that this could be done by going to the hash value index of the array, and then checking the value there. If the value is there and it's not equal to what we're searching for, and there's data at a neighboring address, keep checking until a "gap" is reached. This might work, but what about the instances of data that is removed? And what happens when the array starts to get so full that clusters of data start intersecting with each other?}
{\rtlch\ab0\ltrch\hich\ab0\dbch\ab0\loch\b0\par}\pard\plain \s3\ilvl2\outlinelevel2\sb140\sa120\rtlch\af10\afs28\ab\ltrch\hich\af3\afs28\ab\dbch\af9\loch\f3\fs28\b\ql\fi0\li0\lin0\ri0\rin0\ltrpar{\rtlch\afs24\ab\ltrch\fs24\b
L}{\rtlch\afs24\ab\ltrch\fs24\b
oad Factor and P}{\rtlch\afs24\ab\ltrch\fs24\b
e}{\rtlch\afs24\ab\ltrch\fs24\b
rformance Decay}
{\rtlch\afs24\ab\ltrch\hich\afs24\ab\dbch\afs24\ab\loch\fs24\b\par}\pard\plain \s18\sl276\slmult1\sb0\sa140\ql\fi0\li0\lin0\ri0\rin0\ltrpar{\rtlch\afs24\ab0\ltrch\fs24\b0
The load factor (\u955\'3f) is simply the proportion of the array that is full (\u955\'3f=items/size). With linear probing, you ideally want a load factor of less than 60% to minimize the number of operations required for search and insertion. As the load factor nears 100%, the time complexity "decays" from the average-case O(1) (constant time) toward the worst-case O(N) (linear time). This occurs because the number of steps required to find an open slot or a key starts to approach the size of the array (N).}
{\rtlch\afs24\ab0\ltrch\hich\afs24\ab0\dbch\afs24\ab0\loch\fs24\b0\par}\pard\plain \s3\ilvl2\outlinelevel2\sb140\sa120\rtlch\af10\afs28\ab\ltrch\hich\af3\afs28\ab\dbch\af9\loch\f3\fs28\b\sl276\slmult1\ql\sb0\sa140\ltrpar{\rtlch\afs24\ab\ltrch\fs24\b
Primary Clustering}
{\rtlch\afs24\ab\ltrch\hich\afs24\ab\dbch\afs24\ab\loch\fs24\b\par}\pard\plain \s18\sl276\slmult1\sb0\sa140\ql\fi0\li0\lin0\ri0\rin0\ltrpar{\rtlch\afs24\ab0\ltrch\fs24\b0
Clustering is the phenomenon where contiguous blocks of occupied slots form . This is also known as Primary Clustering in linear probing. It happens because if slot X is full, new data is inserted at X+1. This creates an ever-growing cluster. As the load factor increases, the chance of a new item intersecting an existing cluster grows, forcing subsequent insertions and lookups to search through the entire block, severely degrading performance.}
{\rtlch\afs24\ab0\ltrch\hich\afs24\ab0\dbch\afs24\ab0\loch\fs24\b0\par}\pard\plain \s3\ilvl2\outlinelevel2\sb140\sa120\rtlch\af10\afs28\ab\ltrch\hich\af3\afs28\ab\dbch\af9\loch\f3\fs28\b\sl276\slmult1\ql\sb0\sa140\ltrpar{\rtlch\afs24\ab\ltrch\fs24\b
Double Hashing and the Risk of Cycles}
{\rtlch\afs24\ab\ltrch\hich\afs24\ab\dbch\afs24\ab\loch\fs24\b\par}\pard\plain \s18\sl276\slmult1\sb0\sa140\ql\fi0\li0\lin0\ri0\rin0\ltrpar{\rtlch\afs24\ab0\ltrch\fs24\b0
This issue led to the development of Double Hashing. Instead of just checking the neighboring index upon a collision, a second hash function (h2\u8203\'3f(k)) is used to generate a }{\rtlch\afs24\ab0\ltrch\fs24\i\b0
non-linear}{\rtlch\afs24\ab0\ltrch\fs24\b0
 step distance. For example, if h2\u8203\'3f(k) returns the number 8, the algorithm will probe at (collision_loc+8), (collision_loc+16), and so on, until an empty slot is found.}
{\rtlch\afs24\ab0\ltrch\hich\afs24\ab0\dbch\afs24\ab0\loch\fs24\b0\par}\pard\plain \s18\sl276\slmult1\sb0\sa140\ql\fi0\li0\lin0\ri0\rin0\ltrpar{\rtlch\afs24\ab0\ltrch\fs24\b0
This method, however, introduces the risk of }{\rtlch\afs24\ab0\ltrch\fs24\b0
cycles}{\rtlch\afs24\ab0\ltrch\fs24\b0
. A cycle is achieved when the probing sequence repeats an index that has already been checked }{\rtlch\afs24\ab0\ltrch\fs24\b0
before}{\rtlch\afs24\ab0\ltrch\fs24\b0
 finding an empty slot, even though other empty slots may exist in the table . This failure typically occurs when the hash table size (A) and the step size (h2\u8203\'3f(k)) share a }{\rtlch\afs24\ab0\ltrch\fs24\b0
greatest common divisor (GCD) greater than 1}{\rtlch\afs24\ab0\ltrch\fs24\b0
. If a cycle is detected, the table is usually }{\rtlch\afs24\ab0\ltrch\fs24\b0
resized}{\rtlch\afs24\ab0\ltrch\fs24\b0
 by inst}{\rtlch\afs24\ltrch\fs24
antiating a new, larger array and copying the existing data over (a process called }{\rtlch\afs24\ltrch\fs24\i
re-hashing}{\rtlch\afs24\ltrch\fs24
).}
\par \pard\plain \s3\ilvl2\outlinelevel2\sb140\sa120\rtlch\af10\afs28\ab\ltrch\hich\af3\afs28\ab\dbch\af9\loch\f3\fs28\b\sl276\slmult1\ql\sb0\sa140\ltrpar{\rtlch\ab0\ltrch\b0
2. Chaining (Closed Addressing)}
{\rtlch\ab0\ltrch\hich\ab0\dbch\ab0\loch\b0\par}\pard\plain \s18\sl276\slmult1\sb0\sa140\ql\ltrpar{\rtlch\ab0\ltrch\b0
The second method of implementing a hash table, and the method I used in this problem, is known as "closed addressing." Closed addressing has this name because the result of the hash function is ALWAYS the location the input data is stored at.}
{\rtlch\ab0\ltrch\hich\ab0\dbch\ab0\loch\b0\par}\pard\plain \s18\sl276\slmult1\sb0\sa140\ql\ltrpar{\rtlch\ab0\ltrch\b0
This is possible because a closed address hash table is an array of linked lists. The "parent" array has either NULL or a "node" pointer at each index, and in the case of a collision, a "node" is simply "prepended" to the linked list whose head is at the index location.}
{\rtlch\ab0\ltrch\hich\ab0\dbch\ab0\loch\b0\par}\pard\plain \s18\sl276\slmult1\sb0\sa140\ql\ltrpar{\rtlch\ab0\ltrch\b0
The advantage of this method is simplicity. It seems more complex, but unlike with linear probing, we don't have to worry about load factor being so low, and we don't have to worry about cycles, and we don't have to worry about data deletion creating hurdles.}
{\rtlch\ab0\ltrch\hich\ab0\dbch\ab0\loch\b0\par}\pard\plain \s18\sl276\slmult1\sb0\sa140\ql\ltrpar{\rtlch\ab0\ltrch\b0
The main issue, though, is speed. It's much slower to traverse a linked list than it is to iterate over an array, so as collisions increase, it is my assumption that performance would degrade faster with this method.}
{\rtlch\ab0\ltrch\hich\ab0\dbch\ab0\loch\b0\par}\pard\plain \s3\ilvl2\outlinelevel2\sb140\sa120\rtlch\af10\afs28\ab\ltrch\hich\af3\afs28\ab\dbch\af9\loch\f3\fs28\b\sl276\slmult1\ql\sb0\sa140\ltrpar{\rtlch\ab0\ltrch\b0
Conclusion}
{\rtlch\ab0\ltrch\hich\ab0\dbch\ab0\loch\b0\par}\pard\plain \s18\sl276\slmult1\sb0\sa140\ql\fi0\li0\lin0\ri0\rin0\ltrpar{\rtlch\ab0\ltrch\b0
Ideally, both implementations of a hash map would have O(1), i.e., "constant time," for insertion, deletion, and search. In reality, this isn't ever quite the case, and in a truly terrible implementation, the speed could be linear, much like the na\u239\'efve solution. We can imagine an array of size one forcing every piece of data to collide and just become a linked list with extra steps. Or a hash algorithm that doesn't properly "avalanche," and ends up causing clustering.}
{\rtlch\ab0\ltrch\hich\ab0\dbch\ab0\loch\b0\par}\pard\plain \s18\sl276\slmult1\sb0\sa140\ql\ltrpar{\rtlch\ab0\ltrch\b0
But in general, this data structure is much faster than an array at lookups and deletions.}
{\rtlch\ab0\ltrch\hich\ab0\dbch\ab0\loch\b0\par}\pard\plain \s18\sl276\slmult1\sb0\sa140\ql\sb0\sa140\ltrpar\rtlch\ab0\ltrch\b0

{\rtlch\ab0\ltrch\hich\ab0\dbch\ab0\loch\b0\par}}